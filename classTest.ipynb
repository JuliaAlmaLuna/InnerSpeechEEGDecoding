{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataLoader as dl\n",
    "\n",
    "\n",
    "#from Inner_Speech_Dataset.Plotting.ERPs import \n",
    "from Inner_Speech_Dataset.Python_Processing.Data_extractions import  Extract_data_from_subject\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Select_time_window, Transform_for_classificator, Split_trial_in_time\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Calculate_power_windowed\n",
    "from Inner_Speech_Dataset.Python_Processing.Utilitys import picks_from_channels\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import Average_in_frec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequencies\n",
    "\n",
    "from scipy.fft import rfft, ifft, fftshift, fftfreq\n",
    "\n",
    "\n",
    "#Separate into equal 5 buckets\n",
    "def sepFreqIndexBuckets(freqs2, nr_of_buckets = 5): \n",
    "     \n",
    "    bucket_size_amp = np.sum(freqs2)/nr_of_buckets\n",
    "    #print(bucket_size_amp)\n",
    "    \n",
    "    buckets = np.zeros([nr_of_buckets, 2])\n",
    "    bucket = []\n",
    "    cur_buck_size = 0\n",
    "    \n",
    "    b = 0\n",
    "    c = 0\n",
    "    for index, freqs in enumerate(freqs2,0):\n",
    "        cur_buck_size += freqs\n",
    "        bucket.append(index)\n",
    "        if cur_buck_size > bucket_size_amp:\n",
    "            buckets[b] = [0 + c , c + len(bucket)]\n",
    "            b += 1\n",
    "            c += len(bucket)\n",
    "            #print(len(bucket))\n",
    "            bucket = []\n",
    "            cur_buck_size = 0\n",
    "            \n",
    "    \n",
    "    buckets[b] = [0 + c , c + len(bucket)]\n",
    "    #print(len(bucket)) \n",
    "       \n",
    "    return buckets  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createFreqBuckets(data, nr_of_buckets = 5):\n",
    "\n",
    "\n",
    "    nr_of_buckets = 5\n",
    "    buckets = np.zeros([nr_of_buckets, 2])\n",
    "    for trial in data:\n",
    "        for channel in trial:\n",
    "            buckets += sepFreqIndexBuckets(abs(rfft(channel))[:(channel.shape[0]//2)], nr_of_buckets)\n",
    "            \n",
    "    buckets = buckets/(data.shape[0]*data.shape[1])\n",
    "    \n",
    "    \n",
    "    return np.int32(buckets)\n",
    "\n",
    "\n",
    "def data_into_freq_buckets(data, nr_of_buckets, buckets):\n",
    "\n",
    "    freqAmps = np.zeros([data.shape[0], data.shape[1], nr_of_buckets])\n",
    "    for tr_nr, trial in enumerate(data):\n",
    "        for ch_nr, channel in enumerate(trial):\n",
    "            for b in range(nr_of_buckets):\n",
    "                ff_c = abs(rfft(channel))*1000\n",
    "                freqAmps[tr_nr, ch_nr, b] = np.sum(ff_c[int(buckets[b, 0]):int(buckets[b,1])])\n",
    "    return freqAmps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: [trials x channels x samples]\n",
      "(500, 128, 128)\n",
      "Labels shape\n",
      "(500, 4)\n",
      "Final data shape\n",
      "(100, 128, 128)\n",
      "Final labels shape\n",
      "(100,)\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "(788, 128, 128)\n",
      "(788, 128)\n",
      "(788, 128)\n",
      "(788, 128)\n",
      "(788, 128)\n",
      "(788, 4, 128)\n",
      "(788, 4, 2)\n",
      "buckets\n",
      "[[ 0  3]\n",
      " [ 3  8]\n",
      " [ 8 19]\n",
      " [19 40]\n",
      " [40 63]]\n",
      "(788, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "#Channel name array\n",
    "\n",
    "def arrToDict(arr):\n",
    "    dict = {}\n",
    "    for row in arr:\n",
    "        dict[row[0]] = row[1]\n",
    "    \n",
    "    return dict\n",
    "\n",
    "def get_channelNames():\n",
    "    ch_names = np.array(dl.get_channelnames())\n",
    "    nr = np.arange(ch_names.shape[0])\n",
    "    ch_names = np.array([ch_names, nr]).T\n",
    "    ch_names = arrToDict(ch_names)\n",
    "    return ch_names\n",
    "\n",
    "def only_spec_channel_data(data , picks):\n",
    "    \n",
    "    channel_names_string = picks_from_channels(picks)\n",
    "    ch_names = get_channelNames()\n",
    "    channel_nr = []\n",
    "    for name in  channel_names_string:\n",
    "        channel_nr.append(int(ch_names[name]))\n",
    "        #print(ch_names[name])\n",
    "\n",
    "    channel_nr = np.array(channel_nr)\n",
    "    \n",
    "    #print(channel_nr)\n",
    "    #data = np.swapaxes(data, 0, 1)\n",
    "    #labels = np.swapaxes(labels, 0, 1)\n",
    "    #for channelnrs in channels:\n",
    "    data2 = np.delete(data, np.delete(np.arange(128), channel_nr) , axis=1)\n",
    "    return data2\n",
    "\n",
    "\n",
    "def get_power_array(split_data , samplingRate, trialSplit = 1, t_min = 0, t_max = 1):\n",
    "\n",
    "    #trialSplit = 16\n",
    "    sR = samplingRate #samplingRate = 32\n",
    "    data_power = np.zeros([split_data.shape[0], split_data.shape[1], trialSplit, 2])\n",
    "    for t, trial in enumerate(split_data,0):\n",
    "        for c, channel in enumerate(trial,0):\n",
    "            for x in range(trialSplit):\n",
    "                data_power[t, c, x, : ] = Calculate_power_windowed(channel, fc=sR, window_len=sR/8, window_step=sR/8, t_min=t_min*(1/trialSplit), t_max=t_max*(1/trialSplit))\n",
    "    \n",
    "\n",
    "    #m_power , std_power\n",
    "    #print(data_power.shape)\n",
    "    return data_power\n",
    "    \n",
    "\n",
    "\n",
    "#Loading the data and labels from EEG and EXG\n",
    "\n",
    "# data1, labels1 = dl.load_data(datatype=\"EEG\", subject_nr=1, verbose=True,sampling_rate=sampling_rate) \n",
    "# data2, labels2 = dl.load_data(datatype=\"EEG\", subject_nr=2 ,verbose=True,sampling_rate=sampling_rate )\n",
    "# data4 , labels4 = dl.load_data(datatype=\"EEG\", subject_nr=4, verbose=True,sampling_rate=sampling_rate) \n",
    "\n",
    "# dataX, labelsX = dl.load_data(datatype=\"EXG\", verbose=False) \n",
    "# #datab, labelsb = dl.load_data(datatype=\"baseline\", verbose=False, sampling_rate=32) \n",
    "# #dl.load_data(datatype2=2) #4.5 is max\n",
    "\n",
    "####\n",
    "\n",
    "#data = np.concatenate([data1, data2, data4], axis = 0)\n",
    "#labels1d = np.concatenate([labels1, labels2, labels4], axis = 0)\n",
    "\n",
    "####\n",
    "\n",
    "#data = data1\n",
    "#labels1d = labels1\n",
    "\n",
    "sampling_rate = 128\n",
    "nr_of_datasets=8\n",
    "data, labels = dl.load_multiple_datasets(nr_of_datasets=nr_of_datasets, sampling_rate=sampling_rate, t_min=2, t_max=3)\n",
    "\n",
    "ch_names = get_channelNames()\n",
    "\n",
    "print(data.shape)\n",
    "dataCL = only_spec_channel_data(data, \"CL\")\n",
    "dataCZ = only_spec_channel_data(data, \"CZ\")\n",
    "dataPZ = only_spec_channel_data(data, \"PZ\")\n",
    "dataOPZ = only_spec_channel_data(data, \"OPZ\")\n",
    "\n",
    "def avg_channels(data):\n",
    "    avg_data = np.mean(data, axis=1)\n",
    "    print(avg_data.shape)\n",
    "    return np.reshape(avg_data, [avg_data.shape[0], 1 , avg_data.shape[1]])\n",
    "\n",
    "data = np.concatenate([avg_channels(dataCL), avg_channels(dataCZ),\n",
    "                avg_channels(dataPZ), avg_channels(dataOPZ),], axis=1)\n",
    "print(data.shape)\n",
    "\n",
    "#Not work when time is not 4.5 right now kinda\n",
    "print(data.shape)\n",
    "data_p =  get_power_array(data[:,:128,:], sampling_rate, trialSplit=1).squeeze()\n",
    "print(data_p.shape)\n",
    "\n",
    "#Getting Freq Data \n",
    "nr_of_buckets = 5\n",
    "buckets = createFreqBuckets(data[:,:128,:], nr_of_buckets)\n",
    "print(\"buckets\")\n",
    "print(buckets)\n",
    "data_f = data_into_freq_buckets(data[:,:128,:], nr_of_buckets, buckets)\n",
    "#data_f = np.concatenate([dataf, np.zeros([data_f.shape[0], nr_of_datasets, data_f.shape[2]])], axis=1)\n",
    "\n",
    "print(data_f.shape)\n",
    "\n",
    "\n",
    "## Normalize data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(788, 4, 5)\n",
      "(788, 4, 2)\n",
      "(788, 2)\n",
      "(788, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data_f.shape)\n",
    "print(data_p.shape)\n",
    "print(labels.shape)\n",
    "data = np.concatenate([data_f, data_p], axis =2 )\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_local_frequency(split_data , samplingRate, trialSplit = 2,):\n",
    "\n",
    "#     #trialSplit = 16\n",
    "#     sR = samplingRate #samplingRate = 32\n",
    "#     data_power = np.zeros([split_data.shape[0], split_data.shape[1], trialSplit, 2])\n",
    "#     for t, trial in enumerate(split_data,0):\n",
    "#         for c, channel in enumerate(trial,0):\n",
    "#             for x in range(trialSplit):\n",
    "#                 data_power[t, c, x, : ] = Calculate_power_windowed(channel, fc=sR, window_len=1*4/trialSplit, window_step=1*4/trialSplit, t_min=0, t_max=4/trialSplit * x + 4/trialSplit)\n",
    "    \n",
    "\n",
    "#     #m_power , std_power\n",
    "#     #print(data_power.shape)\n",
    "#     return data_power\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 2)\n",
      "(591, 4, 7)\n",
      "(197, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into training and test data\n",
    "#print(labels)\n",
    "\n",
    "\n",
    "order = np.arange(labels.shape[0])\n",
    "np.random.shuffle(order)\n",
    "\n",
    "temp_data = np.zeros(data.shape)\n",
    "temp_labels = np.zeros(labels.shape)\n",
    "\n",
    "for x in range(labels.shape[0]):\n",
    "    i = order[x]\n",
    "    \n",
    "    temp_data[x] = data[i]\n",
    "    temp_labels[x] = labels[i]\n",
    "\n",
    "data = temp_data\n",
    "labels = temp_labels\n",
    "\n",
    "data_train, data_test = np.split(data, indices_or_sections=[int(labels.shape[0]*0.75)],axis=0)\n",
    "labels_train, labels_test = np.split(labels, indices_or_sections=[int(labels.shape[0]*0.75)],axis=0)\n",
    "print(labels_train.shape)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution part\n",
    "\n",
    "# Do the convs like I wrote in the Note\n",
    "# First need to find out 8 best channels\n",
    "#  Utilities can help average similar channels\n",
    "# Read through article and how they did it better!\n",
    "# convlayer = tf.keras.layers.Conv2D(4,\n",
    "#  kernel_size=[2,1], input_shape= (data_train.shape[0], data_train.shape[1] , data_train.shape[2], 1,), \n",
    "#  padding=\"valid\", strides=[round(data_train.shape[1]),1],\n",
    "#  activation=\"relu\")\n",
    "\n",
    "\n",
    "# print(data_train.shape)\n",
    "# print(data_test.shape)\n",
    "\n",
    "# #data_train = np.swapaxes(data_train, 2, 1)\n",
    "# #data_test = np.swapaxes(data_test, 2, 1)\n",
    "# print(data_train.shape)\n",
    "# print(data_test.shape)\n",
    "# data_train = np.expand_dims(data_train, axis=0)\n",
    "# data_test = np.expand_dims(data_test, axis=0)\n",
    "# data_train = np.moveaxis(data_train, 0, -1)\n",
    "# data_test = np.moveaxis(data_test, 0, -1)\n",
    "\n",
    "# conv_data_train = convlayer(data_train)\n",
    "# conv_data_test = convlayer(data_test)\n",
    "\n",
    "# data_train = conv_data_train\n",
    "# data_test = conv_data_test\n",
    "\n",
    "# #data_train = np.swapaxes(data_train, 2, 1)\n",
    "# #data_test = np.swapaxes(data_test, 2, 1)\n",
    "\n",
    "\n",
    "# data_train = np.squeeze(np.moveaxis(data_train, -1, 0))\n",
    "# data_test = np.squeeze(np.moveaxis(data_test, -1, 0))\n",
    "# print(data_train.shape)\n",
    "# print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# eeg_model = tf.keras.Sequential([\n",
    "    \n",
    "#     #layers.Conv2D(500,\n",
    "#     #kernel_size=[1,8], input_shape= (1, data_train.shape[1], data_train.shape[2], 1,), \n",
    "#     #padding=\"valid\", strides=[1,4],\n",
    "#     #activation=\"relu\"),\n",
    "#     # layers.Conv2D(200,\n",
    "#     # kernel_size=[1,32], \n",
    "#     # padding=\"valid\", strides=1,\n",
    "#     # activation=\"relu\"),\n",
    "#     # layers.Conv2D(200,\n",
    "#     # kernel_size=[1,32], \n",
    "#     # padding=\"valid\", strides=1,\n",
    "#     # activation=\"relu\"),\n",
    "#     # layers.Conv2D(200,\n",
    "#     # kernel_size=[1,32], \n",
    "#     # padding=\"valid\", strides=4,\n",
    "#     # activation=\"relu\"),\n",
    "#     layers.LocallyConnected1D(56, input_shape = (data_train.shape[1],data_train.shape[2]), \n",
    "#      kernel_size=50, \n",
    "#      padding=\"valid\", strides=1,\n",
    "#      activation=\"relu\"),\n",
    "#     layers.Dropout(0.2),\n",
    "#     #layers.Flatten(input_shape = (data_train.shape[1],data_train.shape[2])),\n",
    "#     #layers.Dense(units=28*3, activation=\"relu\"),\n",
    "#     #layers.Dropout(0.3),\n",
    "#     layers.Dense(units=500, activation=\"relu\"),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.LocallyConnected1D(56, \n",
    "#     kernel_size=30, \n",
    "#     padding=\"valid\", strides=1,\n",
    "#     activation=\"relu\"),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.Dense(units=500, activation=\"relu\"),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.LocallyConnected1D(56, \n",
    "#     kernel_size=20, \n",
    "#     padding=\"valid\", strides=1,\n",
    "#     activation=\"relu\"),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.Dense(units=500, activation=\"relu\"),\n",
    "#     layers.Dropout(0.2),\n",
    "#     #layers.Dense(units=20, activation=\"relu\"),\n",
    "#     #layers.Dense(units=5, activation=\"relu\"),\n",
    "#     #layers.Dense(units=1, activation=\"relu\"),\n",
    "#     layers.Flatten(),\n",
    "#     # layers.Dropout(0.4),\n",
    "#     # layers.Dense(units=28*28, activation=\"relu\"),\n",
    "#     # layers.Dropout(0.4),\n",
    "#     # layers.Dense(units=28, activation=\"relu\"),\n",
    "#     # layers.Dropout(0.4),\n",
    "#     layers.Dense(units=2, activation=\"softmax\")\n",
    "\n",
    "\n",
    "# ])\n",
    "# eeg_model.build()\n",
    "# eeg_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " locally_connected1d (Locall  (None, 50, 56)           11342800  \n",
      " yConnected1D)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 56)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50, 500)           28500     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50, 500)           0         \n",
      "                                                                 \n",
      " locally_connected1d_1 (Loca  (None, 31, 10)           3100310   \n",
      " llyConnected1D)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 31, 10)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 31, 200)           2200      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 31, 200)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6200)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 12402     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,486,212\n",
      "Trainable params: 14,486,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eeg_model = tf.keras.Sequential([\n",
    "    \n",
    "    #layers.Conv2D(500,\n",
    "    #kernel_size=[1,8], input_shape= (1, data_train.shape[1], data_train.shape[2], 1,), \n",
    "    #padding=\"valid\", strides=[1,4],\n",
    "    #activation=\"relu\"),\n",
    "    # layers.Conv2D(200,\n",
    "    # kernel_size=[1,32], \n",
    "    # padding=\"valid\", strides=1,\n",
    "    # activation=\"relu\"),\n",
    "    # layers.Conv2D(200,\n",
    "    # kernel_size=[1,32], \n",
    "    # padding=\"valid\", strides=1,\n",
    "    # activation=\"relu\"),\n",
    "    # layers.Conv2D(200,\n",
    "    # kernel_size=[1,32], \n",
    "    # padding=\"valid\", strides=4,\n",
    "    # activation=\"relu\"),\n",
    "    layers.LocallyConnected1D(56, input_shape = (data_train.shape[1],data_train.shape[2]), \n",
    "     kernel_size=30, \n",
    "     padding=\"valid\", strides=2,\n",
    "     activation=\"relu\"),\n",
    "    layers.Dropout(0.7),\n",
    "    #layers.Flatten(input_shape = (data_train.shape[1],data_train.shape[2])),\n",
    "    #layers.Dense(units=28*3, activation=\"relu\"),\n",
    "    # layers.Dropout(0.3),\n",
    "    # layers.Dense(units=500, activation=\"relu\"),\n",
    "    # layers.Dropout(0.5),\n",
    "    # layers.LocallyConnected1D(56, \n",
    "    # kernel_size=30, \n",
    "    # padding=\"valid\", strides=1,\n",
    "    # activation=\"relu\"),\n",
    "    #layers.Dropout(0.7),\n",
    "    #layers.Dense(units=500, activation=\"relu\"),\n",
    "    #layers.Dropout(0.8),\n",
    "    layers.LocallyConnected1D(10, \n",
    "    kernel_size=20, \n",
    "    padding=\"valid\", strides=1,\n",
    "    activation=\"relu\"),\n",
    "    layers.Dropout(0.8),\n",
    "    layers.Dense(units=200, activation=\"relu\"),\n",
    "    layers.Dropout(0.8),\n",
    "    #layers.Dense(units=20, activation=\"relu\"),\n",
    "    #layers.Dense(units=5, activation=\"relu\"),\n",
    "    #layers.Dense(units=1, activation=\"relu\"),\n",
    "    #layers.Flatten(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(units=28*28, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(units=28, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(units=2, activation=\"softmax\")\n",
    "\n",
    "\n",
    "])\n",
    "eeg_model.build()\n",
    "eeg_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trialNr, trial in enumerate(data_train[46:47],1):\n",
    "    for channel in trial[3:4]:\n",
    "        plt.figure()\n",
    "        plt.plot(channel)\n",
    "        plt.title(\"EEG {}\".format(labels_train[trialNr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 5s 214ms/step - loss: 0.7037 - accuracy: 0.4953 - val_loss: 0.6959 - val_accuracy: 0.4500\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 0.7103 - accuracy: 0.5141 - val_loss: 0.6942 - val_accuracy: 0.4333\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 3s 193ms/step - loss: 0.7142 - accuracy: 0.4972 - val_loss: 0.6975 - val_accuracy: 0.4667\n",
      "Epoch 4/50\n",
      " 5/17 [=======>......................] - ETA: 2s - loss: 0.7181 - accuracy: 0.5188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\PythonProjects\\NietoExcercise-1\\classTest.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m data_test_send \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(data_test, [data_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m , data_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], data_test\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], \u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m eeg_model\u001b[39m.\u001b[39;49mfit(data_train, labels_train, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m ,callbacks\u001b[39m=\u001b[39;49m[callback], epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m) \u001b[39m#\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mResults\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m eeg_model\u001b[39m.\u001b[39mevaluate(data_test, labels_test)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "#callback2 = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(histogram_freq=2)\n",
    "\n",
    "eeg_model.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "data_train_send = np.reshape(data_train, [data_train.shape[0], 1 , data_train.shape[1], data_train.shape[2], 1])\n",
    "#data_train_send = np.reshape(data_train, [data_train.shape[0], 1 , data_train.shape[1], data_train.shape[2], 1])\n",
    "\n",
    "data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\n",
    "#data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\n",
    "\n",
    "outputs = eeg_model.fit(data_train, labels_train, validation_split=0.1 ,callbacks=[callback], epochs=50) #\n",
    "\n",
    "print(\"Results\")\n",
    "eeg_model.evaluate(data_test, labels_test)\n",
    "result = eeg_model.predict(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model6\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eeg_model.save('saved_model/my_model6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 0.6953 - accuracy: 0.4619\n",
      "7/7 [==============================] - 1s 123ms/step\n",
      "[[0.47737655 0.52262354]\n",
      " [0.38966712 0.6103329 ]\n",
      " [0.47881296 0.521187  ]\n",
      " [0.47822347 0.52177656]\n",
      " [0.4693499  0.53065014]\n",
      " [0.4776438  0.5223562 ]\n",
      " [0.47772625 0.5222737 ]\n",
      " [0.4635916  0.5364084 ]\n",
      " [0.47336978 0.5266303 ]\n",
      " [0.46468732 0.53531265]\n",
      " [0.47645646 0.5235436 ]\n",
      " [0.476968   0.523032  ]\n",
      " [0.47442225 0.5255778 ]\n",
      " [0.47561613 0.52438384]\n",
      " [0.462317   0.537683  ]\n",
      " [0.4646464  0.53535354]\n",
      " [0.3883958  0.6116042 ]\n",
      " [0.47151524 0.5284848 ]\n",
      " [0.45204785 0.5479521 ]\n",
      " [0.47794533 0.5220547 ]\n",
      " [0.43207544 0.56792456]\n",
      " [0.45140547 0.5485946 ]\n",
      " [0.47822794 0.521772  ]\n",
      " [0.4631676  0.53683245]\n",
      " [0.47533414 0.5246659 ]\n",
      " [0.4682925  0.5317075 ]\n",
      " [0.47703227 0.5229677 ]\n",
      " [0.47797903 0.52202094]\n",
      " [0.42021608 0.5797839 ]\n",
      " [0.46835703 0.53164303]\n",
      " [0.47778246 0.52221763]\n",
      " [0.47732425 0.52267575]\n",
      " [0.45689324 0.54310673]\n",
      " [0.46090165 0.5390983 ]\n",
      " [0.41844654 0.5815534 ]\n",
      " [0.46778393 0.532216  ]\n",
      " [0.42523128 0.5747688 ]\n",
      " [0.4592637  0.54073626]\n",
      " [0.46927673 0.5307233 ]\n",
      " [0.4602691  0.5397309 ]\n",
      " [0.40659925 0.5934007 ]\n",
      " [0.4211809  0.5788191 ]\n",
      " [0.4765577  0.5234423 ]\n",
      " [0.46305537 0.5369446 ]\n",
      " [0.46543005 0.5345699 ]\n",
      " [0.44647586 0.5535241 ]\n",
      " [0.4273978  0.5726023 ]\n",
      " [0.45575052 0.54424953]\n",
      " [0.47768745 0.52231264]\n",
      " [0.47286916 0.52713084]\n",
      " [0.47178537 0.52821463]\n",
      " [0.47767657 0.5223234 ]\n",
      " [0.4786227  0.52137727]\n",
      " [0.37229174 0.62770826]\n",
      " [0.47781163 0.5221884 ]\n",
      " [0.4779577  0.52204233]\n",
      " [0.4786112  0.52138877]\n",
      " [0.40900084 0.5909992 ]\n",
      " [0.46869352 0.5313065 ]\n",
      " [0.4708792  0.5291208 ]\n",
      " [0.41932574 0.58067423]\n",
      " [0.47883013 0.5211699 ]\n",
      " [0.40327948 0.5967205 ]\n",
      " [0.4760297  0.5239703 ]\n",
      " [0.45047835 0.5495216 ]\n",
      " [0.46706203 0.532938  ]\n",
      " [0.44723403 0.55276597]\n",
      " [0.47662395 0.52337605]\n",
      " [0.45988756 0.5401125 ]\n",
      " [0.47878534 0.52121466]\n",
      " [0.44002804 0.5599719 ]\n",
      " [0.4308485  0.56915146]\n",
      " [0.4228876  0.5771124 ]\n",
      " [0.4748878  0.52511215]\n",
      " [0.42954224 0.5704577 ]\n",
      " [0.4506463  0.54935366]\n",
      " [0.45506805 0.544932  ]\n",
      " [0.44473073 0.5552693 ]\n",
      " [0.47873524 0.5212648 ]\n",
      " [0.4561036  0.5438963 ]\n",
      " [0.47789812 0.5221019 ]\n",
      " [0.45895004 0.54104996]\n",
      " [0.47894466 0.52105534]\n",
      " [0.4790051  0.52099484]\n",
      " [0.4716401  0.5283599 ]\n",
      " [0.47685674 0.52314323]\n",
      " [0.46479902 0.535201  ]\n",
      " [0.44130605 0.55869395]\n",
      " [0.39656913 0.6034308 ]\n",
      " [0.47633168 0.5236683 ]\n",
      " [0.4702643  0.5297357 ]\n",
      " [0.47749487 0.52250516]\n",
      " [0.47712505 0.52287495]\n",
      " [0.41252503 0.587475  ]\n",
      " [0.42556983 0.57443017]\n",
      " [0.47716057 0.5228394 ]\n",
      " [0.37623098 0.62376904]\n",
      " [0.47848552 0.52151453]\n",
      " [0.47813624 0.52186376]\n",
      " [0.47832775 0.52167225]\n",
      " [0.39692014 0.60307986]\n",
      " [0.46423846 0.5357615 ]\n",
      " [0.47807348 0.52192646]\n",
      " [0.47742724 0.5225727 ]\n",
      " [0.4686736  0.5313264 ]\n",
      " [0.4761539  0.52384615]\n",
      " [0.46415344 0.5358466 ]\n",
      " [0.40874892 0.591251  ]\n",
      " [0.4783392  0.5216608 ]\n",
      " [0.45029855 0.54970145]\n",
      " [0.46888977 0.5311102 ]\n",
      " [0.4781486  0.5218514 ]\n",
      " [0.45899016 0.54100984]\n",
      " [0.42704874 0.57295126]\n",
      " [0.46023735 0.5397627 ]\n",
      " [0.47852606 0.52147394]\n",
      " [0.46105352 0.53894645]\n",
      " [0.4772265  0.5227735 ]\n",
      " [0.47585136 0.5241487 ]\n",
      " [0.47030595 0.52969396]\n",
      " [0.4779967  0.52200323]\n",
      " [0.46668014 0.5333199 ]\n",
      " [0.46712437 0.5328756 ]\n",
      " [0.47759566 0.5224043 ]\n",
      " [0.4768057  0.5231943 ]\n",
      " [0.47815382 0.52184623]\n",
      " [0.47792843 0.5220716 ]\n",
      " [0.45028725 0.5497127 ]\n",
      " [0.4610364  0.53896356]\n",
      " [0.4614034  0.5385966 ]\n",
      " [0.38581896 0.614181  ]\n",
      " [0.47027895 0.5297211 ]\n",
      " [0.47828573 0.5217143 ]\n",
      " [0.4677453  0.53225464]\n",
      " [0.47173136 0.5282686 ]\n",
      " [0.45859075 0.5414092 ]\n",
      " [0.478309   0.521691  ]\n",
      " [0.47863138 0.5213687 ]\n",
      " [0.40741268 0.5925873 ]\n",
      " [0.47031558 0.5296844 ]\n",
      " [0.43535432 0.56464565]\n",
      " [0.4254659  0.5745341 ]\n",
      " [0.4287998  0.5712002 ]\n",
      " [0.4603323  0.53966767]\n",
      " [0.43731973 0.56268024]\n",
      " [0.43681586 0.5631842 ]\n",
      " [0.47432524 0.5256747 ]\n",
      " [0.46270537 0.5372947 ]\n",
      " [0.46388534 0.53611463]\n",
      " [0.4120974  0.5879026 ]\n",
      " [0.47334832 0.52665174]\n",
      " [0.4259845  0.5740155 ]\n",
      " [0.41114476 0.58885527]\n",
      " [0.47854382 0.52145624]\n",
      " [0.47828314 0.52171683]\n",
      " [0.4393684  0.56063163]\n",
      " [0.46476033 0.5352397 ]\n",
      " [0.43905511 0.56094486]\n",
      " [0.40538305 0.59461695]\n",
      " [0.45899057 0.54100937]\n",
      " [0.45933723 0.54066277]\n",
      " [0.43087596 0.5691241 ]\n",
      " [0.43111908 0.5688809 ]\n",
      " [0.42613444 0.5738656 ]\n",
      " [0.43599346 0.56400657]\n",
      " [0.42832184 0.5716782 ]\n",
      " [0.4772612  0.5227389 ]\n",
      " [0.4758061  0.5241939 ]\n",
      " [0.42486426 0.57513577]\n",
      " [0.46195918 0.5380408 ]\n",
      " [0.4709541  0.529046  ]\n",
      " [0.47630048 0.5236996 ]\n",
      " [0.47646287 0.5235371 ]\n",
      " [0.46365702 0.5363429 ]\n",
      " [0.47879916 0.5212008 ]\n",
      " [0.47239432 0.52760565]\n",
      " [0.47403416 0.5259658 ]\n",
      " [0.4550121  0.5449879 ]\n",
      " [0.4590749  0.5409251 ]\n",
      " [0.46462744 0.53537256]\n",
      " [0.477528   0.52247196]\n",
      " [0.4764677  0.5235323 ]\n",
      " [0.40972254 0.5902775 ]\n",
      " [0.43403623 0.56596375]\n",
      " [0.47222564 0.5277744 ]\n",
      " [0.47696066 0.5230394 ]\n",
      " [0.47301996 0.52698004]\n",
      " [0.47817668 0.52182335]\n",
      " [0.47463155 0.5253685 ]\n",
      " [0.4758559  0.5241441 ]\n",
      " [0.41760942 0.58239067]\n",
      " [0.46333492 0.536665  ]\n",
      " [0.42560232 0.5743977 ]\n",
      " [0.47360882 0.52639115]\n",
      " [0.44903573 0.55096424]\n",
      " [0.47832814 0.5216719 ]\n",
      " [0.42027542 0.57972455]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results\")\n",
    "eeg_model.evaluate(data_test, labels_test)\n",
    "result = eeg_model.predict(data_test)\n",
    "\n",
    "result2 = []\n",
    "print(result)\n",
    "for res in result:\n",
    "    x = np.maximum(res[0], res[1])\n",
    "    result2.append(int(np.where(res == x)[0]))\n",
    "\n",
    "result2 = np.array(result2)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for trialNr, trial in enumerate(data[44:46],44):\n",
    "    for channel in trial[5:6]:\n",
    "        plt.figure()\n",
    "        plt.plot(channel)\n",
    "        plt.title(\"EEG {}\".format(labels[trialNr]))\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ForMasterBelgium')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "069d677023565e6a5ddf17d1b4984613dfef886b8c4d74c12f77b96d6ea71cdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
