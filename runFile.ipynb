{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataLoader as dl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import util as ut\n",
    "\n",
    "#from Inner_Speech_Dataset.Plotting.ERPs import \n",
    "from Inner_Speech_Dataset.Python_Processing.Data_extractions import  Extract_data_from_subject\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Select_time_window, Transform_for_classificator, Split_trial_in_time\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Calculate_power_windowed\n",
    "from Inner_Speech_Dataset.Python_Processing.Utilitys import picks_from_channels\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import Average_in_frec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: [trials x channels x samples]\n",
      "(500, 128, 256)\n",
      "Labels shape\n",
      "(500, 4)\n",
      "Final data shape\n",
      "(100, 128, 256)\n",
      "Final labels shape\n",
      "(100,)\n",
      "Up is 0.0 and Down is 1.0\n",
      "(100, 128, 256)\n",
      "(100, 128, 2)\n",
      "buckets\n",
      "[[  0   2]\n",
      " [  2   7]\n",
      " [  7  13]\n",
      " [ 13  19]\n",
      " [ 19  28]\n",
      " [ 28  40]\n",
      " [ 40  59]\n",
      " [ 59  83]\n",
      " [ 83 113]\n",
      " [ 80  94]]\n",
      "(100, 128, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sampling_rate = 256\n",
    "nr_of_datasets=1\n",
    "data, labels = dl.load_multiple_datasets(nr_of_datasets=nr_of_datasets, sampling_rate=sampling_rate, t_min=2, t_max=3, twoDLabels=False)\n",
    "\n",
    "ch_names = ut.get_channelNames()\n",
    "\n",
    "print(data.shape)\n",
    "data_p =  ut.get_power_array(data[:,:128,:], sampling_rate, trialSplit=1).squeeze()\n",
    "print(data_p.shape)\n",
    "#print(data_p[:,:,1])\n",
    "\n",
    "#Getting Freq Data \n",
    "nr_of_buckets = 10\n",
    "buckets = ut.createFreqBuckets(data[:,:128,:], nr_of_buckets)\n",
    "print(\"buckets\")\n",
    "print(buckets)\n",
    "data_f = ut.data_into_freq_buckets(data[:,:128,:], nr_of_buckets, buckets)\n",
    "#data_f = np.concatenate([dataf, np.zeros([data_f.shape[0], nr_of_datasets, data_f.shape[2]])], axis=1)\n",
    "\n",
    "print(data_f.shape)\n",
    "\n",
    "\n",
    "## Normalize data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 128, 10)\n",
      "(100, 128, 2)\n",
      "(100,)\n",
      "[9.56732240e-11 4.90024352e-11]\n",
      "(100, 128, 12)\n",
      "(100, 128, 12)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(data_f.shape)#ss\n",
    "print(data_p.shape)\n",
    "print(labels.shape)\n",
    "print(data_p[2,5])\n",
    "data = np.concatenate([data_f, data_p], axis =2 ) #, data\n",
    "print(data.shape)\n",
    "data = keras.utils.normalize(data, axis=1, order=2)\n",
    "print(data.shape)\n",
    "#print(data[2,5])\n",
    "#print(labels[2])\n",
    "print(labels[:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add end of ekg with specific array for each person. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75,)\n",
      "(75, 128, 12)\n",
      "(25, 128, 12)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into training and test data\n",
    "#print(labels)\n",
    "\n",
    "\n",
    "order = np.arange(labels.shape[0])\n",
    "np.random.shuffle(order)\n",
    "\n",
    "temp_data = np.zeros(data.shape)\n",
    "temp_labels = np.zeros(labels.shape)\n",
    "\n",
    "for x in range(labels.shape[0]):\n",
    "    i = order[x]\n",
    "    \n",
    "    temp_data[x] = data[i]\n",
    "    temp_labels[x] = labels[i]\n",
    "\n",
    "data = temp_data\n",
    "labels = temp_labels\n",
    "\n",
    "data_train, data_test = np.split(data, indices_or_sections=[int(labels.shape[0]*0.75)],axis=0)\n",
    "labels_train, labels_test = np.split(labels, indices_or_sections=[int(labels.shape[0]*0.75)],axis=0)\n",
    "print(labels_train.shape)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.1: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.1: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.1: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.1: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.2: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.2: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.2: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.2: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.3: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.3: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.3: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.3: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.4: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.4: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.4: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.4: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.5: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.5: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.5: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.5: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.6: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.6: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.6: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.6: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.7: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.7: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.7: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.7: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.7999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.7999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.7999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.7999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.8999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.8999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.8999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.8999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 0.9999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 0.9999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 0.9999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 0.9999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.0999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.0999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.0999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.0999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.2: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.2: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.2: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.2: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.3: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.3: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.3: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.3: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.4: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.4: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.4: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.4: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.5: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.5: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.5: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.5: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.5999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.5999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.5999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.5999999999999999: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.7: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.7: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.7: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.7: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.8: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.8: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.8: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.8: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 1.9: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 1.9: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 1.9: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 1.9: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 1, kernel linear, C = 2.0: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 2, kernel linear, C = 2.0: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 3, kernel linear, C = 2.0: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.45      0.50        11\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.59      0.58      0.58        25\n",
      "weighted avg       0.59      0.60      0.59        25\n",
      "\n",
      "Result for degree 4, kernel linear, C = 2.0: 0.6\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install sklearn -q\n",
    "from tabnanny import verbose\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def svmPipeline(data_train, data_test, labels_train,\n",
    "    labels_test, kernel=\"linear\", degree=3, gamma=\"auto\", C = 1\n",
    "    , coefs = np.zeros([1, data_train.shape[1]*data_train.shape[2]])):\n",
    "    \n",
    "    anova_filter = SelectKBest(f_classif, k=20)\n",
    "    clf = make_pipeline(anova_filter, StandardScaler() ,  SVC(\n",
    "        gamma=gamma, kernel=kernel, degree=degree, verbose=False, C=C))\n",
    "\n",
    "    clf.fit(np.reshape(data_train, [data_train.shape[0], -1]), labels_train)\n",
    "    predictions = clf.predict(np.reshape(data_test, [data_test.shape[0], -1]))\n",
    "    \n",
    "    print(classification_report(labels_test, predictions))\n",
    "    if kernel == \"linear\":\n",
    "        coefs = coefs + clf[:-1].inverse_transform(clf[-1].coef_)\n",
    "    #print(clf[:-1].inverse_transform(clf[-1].coef_).shape)\n",
    "\n",
    "    correct = np.zeros(labels_test.shape)\n",
    "    correctamount=0\n",
    "    for nr, pred in enumerate(predictions,0):\n",
    "        if pred == labels_test[nr]:\n",
    "            correct[nr] = 1\n",
    "            correctamount +=1\n",
    "\n",
    "\n",
    "    return correctamount/labels_test.shape[0], coefs\n",
    "\n",
    "#[LibSVM]Result for gamma auto, kernel rbf, C = 0.8: 0.6\n",
    "#[LibSVM]Result for gamma scale, kernel rbf, C = 0.8: 0.6\n",
    "coefs = np.zeros([1, data_train.shape[1]*data_train.shape[2]])\n",
    "for kernel in [\"linear\", \"rbf\", \"sigmoid\"]:\n",
    "\n",
    "    for C in np.linspace(0.1,2,20):\n",
    "    \n",
    "        if kernel == \"linear\":\n",
    "            for degree in range(1,5):\n",
    "                res, coefs = svmPipeline(data_train, data_test, labels_train, \n",
    "                labels_test, degree=degree, kernel = kernel, C = C, coefs=coefs)\n",
    "                print(\"Result for degree {}, kernel {}, C = {}: {}\".format(degree, kernel, C,  res))\n",
    "        # else:\n",
    "        #     for gamma in [\"auto\", \"scale\"]:\n",
    "\n",
    "        #         res = svmPipeline(data_train, data_test, labels_train, \n",
    "        #         labels_test, degree=degree, kernel = kernel, gamma=gamma, C = C)\n",
    "        #         print(\"Result for gamma {}, kernel {}, C = {}: {}\".format(gamma, kernel, C, res))\n",
    "\n",
    "coefs = np.reshape(coefs, [128,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   9,  38,  39,  40,  41,  50,  51,  52,  62,  63,  78,  79,\n",
      "       101, 103, 104, 105, 117, 117, 118], dtype=int64), array([ 3,  6,  3,  3,  3,  3,  3,  4,  4,  4,  4, 11, 10,  4,  5,  5,  5,\n",
      "        1, 11,  8], dtype=int64))\n",
      "(128, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.where(coefs!=0))\n",
    "print(coefs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " locally_connected1d (Locall  (None, 15, 20)           54300     \n",
      " yConnected1D)                                                   \n",
      "                                                                 \n",
      " locally_connected1d_1 (Loca  (None, 1, 20)            6020      \n",
      " llyConnected1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 20)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 200)            4200      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 200)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 402       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,922\n",
      "Trainable params: 64,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eeg_model = tf.keras.Sequential([\n",
    "\n",
    "    layers.LocallyConnected1D(20, input_shape = (data_train.shape[1],data_train.shape[2]), \n",
    "     kernel_size=15, \n",
    "     padding=\"valid\", strides=8,\n",
    "     activation=\"relu\"),\n",
    "    \n",
    "    \n",
    "    layers.LocallyConnected1D(20, \n",
    "    kernel_size=15, \n",
    "    padding=\"valid\", strides=5,\n",
    "    activation=\"relu\"),\n",
    "    \n",
    "    layers.Dropout(0.8),\n",
    "    \n",
    "    layers.Dense(units=200, activation=\"relu\"),\n",
    "    \n",
    "    layers.Dropout(0.8),\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(units=2, activation=\"softmax\")\n",
    "\n",
    "\n",
    "])\n",
    "eeg_model.build()\n",
    "eeg_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\PythonProjects\\NietoExcercise-1\\runFile.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/runFile.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m data_test_send \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(data_test, [data_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m , data_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], data_test\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], \u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/runFile.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/runFile.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m eeg_model\u001b[39m.\u001b[39;49mfit(data_train, labels_train, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m ,callbacks\u001b[39m=\u001b[39;49m[callback], epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m) \u001b[39m#\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/runFile.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mResults\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/runFile.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m eeg_model\u001b[39m.\u001b[39mevaluate(data_test, labels_test)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\__autograph_generated_filebshnrkw_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "#callback2 = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(histogram_freq=2)\n",
    "\n",
    "eeg_model.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "data_train_send = np.reshape(data_train, [data_train.shape[0], 1 , data_train.shape[1], data_train.shape[2], 1])\n",
    "#data_train_send = np.reshape(data_train, [data_train.shape[0], 1 , data_train.shape[1], data_train.shape[2], 1])\n",
    "\n",
    "data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\n",
    "#data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\n",
    "\n",
    "outputs = eeg_model.fit(data_train, labels_train, validation_split=0.2 ,callbacks=[callback], epochs=50) #\n",
    "\n",
    "print(\"Results\")\n",
    "eeg_model.evaluate(data_test, labels_test)\n",
    "result = eeg_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model6\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eeg_model.save('saved_model/my_model6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0019 - accuracy: 0.5600\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[7.2694892e-01 2.7305105e-01]\n",
      " [3.8849583e-01 6.1150414e-01]\n",
      " [2.3448229e-02 9.7655177e-01]\n",
      " [1.0121168e-02 9.8987877e-01]\n",
      " [6.9411544e-05 9.9993062e-01]\n",
      " [1.4454442e-01 8.5545564e-01]\n",
      " [1.3466945e-02 9.8653305e-01]\n",
      " [7.4755740e-01 2.5244254e-01]\n",
      " [7.5335383e-02 9.2466462e-01]\n",
      " [8.3851330e-02 9.1614866e-01]\n",
      " [7.8725910e-01 2.1274088e-01]\n",
      " [2.0782053e-01 7.9217941e-01]\n",
      " [1.4555229e-02 9.8544472e-01]\n",
      " [5.3242538e-02 9.4675744e-01]\n",
      " [6.2527745e-03 9.9374723e-01]\n",
      " [5.6260753e-01 4.3739250e-01]\n",
      " [7.4348336e-01 2.5651667e-01]\n",
      " [7.6414049e-01 2.3585953e-01]\n",
      " [4.1789272e-01 5.8210737e-01]\n",
      " [3.9263193e-02 9.6073681e-01]\n",
      " [6.0369277e-01 3.9630726e-01]\n",
      " [7.6168078e-01 2.3831928e-01]\n",
      " [1.8715034e-01 8.1284964e-01]\n",
      " [4.8335150e-02 9.5166487e-01]\n",
      " [1.1280457e-01 8.8719541e-01]]\n",
      "[0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results\")\n",
    "eeg_model.evaluate(data_test, labels_test)\n",
    "result = eeg_model.predict(data_test)\n",
    "\n",
    "result2 = []\n",
    "print(result)\n",
    "for res in result:\n",
    "    x = np.maximum(res[0], res[1])\n",
    "    result2.append(int(np.where(res == x)[0]))\n",
    "\n",
    "result2 = np.array(result2)\n",
    "print(result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ForMasterBelgium')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "069d677023565e6a5ddf17d1b4984613dfef886b8c4d74c12f77b96d6ea71cdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
