{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataLoader as dl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import util as ut\n",
    "\n",
    "#from Inner_Speech_Dataset.Plotting.ERPs import \n",
    "from Inner_Speech_Dataset.Python_Processing.Data_extractions import  Extract_data_from_subject\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Select_time_window, Transform_for_classificator, Split_trial_in_time\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Calculate_power_windowed\n",
    "from Inner_Speech_Dataset.Python_Processing.Utilitys import picks_from_channels\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import Average_in_frec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: [trials x channels x samples]\n",
      "(500, 128, 128)\n",
      "Labels shape\n",
      "(500, 4)\n",
      "Final data shape\n",
      "(100, 128, 128)\n",
      "Final labels shape\n",
      "(100,)\n",
      "Up is 0.0 and Down is 1.0\n",
      "(100, 128, 128)\n",
      "(100, 128, 2)\n",
      "buckets\n",
      "[[ 0  3]\n",
      " [ 3  9]\n",
      " [ 9 19]\n",
      " [19 40]\n",
      " [40 63]]\n",
      "(100, 128, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sampling_rate = 128\n",
    "nr_of_datasets=1\n",
    "data, labels = dl.load_multiple_datasets(nr_of_datasets=nr_of_datasets, sampling_rate=sampling_rate, t_min=2, t_max=3)\n",
    "\n",
    "ch_names = ut.get_channelNames()\n",
    "\n",
    "print(data.shape)\n",
    "data_p =  ut.get_power_array(data[:,:128,:], sampling_rate, trialSplit=1).squeeze()\n",
    "print(data_p.shape)\n",
    "#print(data_p[:,:,1])\n",
    "\n",
    "#Getting Freq Data \n",
    "nr_of_buckets = 5\n",
    "buckets = ut.createFreqBuckets(data[:,:128,:], nr_of_buckets)\n",
    "print(\"buckets\")\n",
    "print(buckets)\n",
    "data_f = ut.data_into_freq_buckets(data[:,:128,:], nr_of_buckets, buckets)\n",
    "#data_f = np.concatenate([dataf, np.zeros([data_f.shape[0], nr_of_datasets, data_f.shape[2]])], axis=1)\n",
    "\n",
    "print(data_f.shape)\n",
    "\n",
    "\n",
    "## Normalize data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 128, 5)\n",
      "(100, 128, 2)\n",
      "(100, 2)\n",
      "[1.01648499e-10 5.52805943e-11]\n",
      "(100, 128, 135)\n",
      "(100, 128, 135)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data_f.shape)\n",
    "print(data_p.shape)\n",
    "print(labels.shape)\n",
    "print(data_p[2,5])\n",
    "data = np.concatenate([data_f, data_p, data], axis =2 )\n",
    "print(data.shape)\n",
    "data = keras.utils.normalize(data, axis=1, order=2)\n",
    "print(data.shape)\n",
    "#print(data[2,5])\n",
    "#print(labels[2])\n",
    "print(labels[:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add end of ekg with specific array for each person. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n",
      "(75, 128, 135)\n",
      "(25, 128, 135)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into training and test data\n",
    "#print(labels)\n",
    "\n",
    "\n",
    "order = np.arange(labels.shape[0])\n",
    "np.random.shuffle(order)\n",
    "\n",
    "temp_data = np.zeros(data.shape)\n",
    "temp_labels = np.zeros(labels.shape)\n",
    "\n",
    "for x in range(labels.shape[0]):\n",
    "    i = order[x]\n",
    "    \n",
    "    temp_data[x] = data[i]\n",
    "    temp_labels[x] = labels[i]\n",
    "\n",
    "data = temp_data\n",
    "labels = temp_labels\n",
    "\n",
    "data_train, data_test = np.split(data, indices_or_sections=[int(labels.shape[0]*0.75)],axis=0)\n",
    "labels_train, labels_test = np.split(labels, indices_or_sections=[int(labels.shape[0]*0.75)],axis=0)\n",
    "print(labels_train.shape)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 128, 135)          0         \n",
      "                                                                 \n",
      " locally_connected1d (Locall  (None, 50, 556)          112617800 \n",
      " yConnected1D)                                                   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50, 556)           0         \n",
      "                                                                 \n",
      " locally_connected1d_1 (Loca  (None, 31, 510)          175823010 \n",
      " llyConnected1D)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 31, 510)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 31, 200)           102200    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 31, 200)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6200)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 12402     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 288,555,412\n",
      "Trainable params: 288,555,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eeg_model = tf.keras.Sequential([\n",
    "    layers.Dropout(0.7, input_shape = (data_train.shape[1],data_train.shape[2])),\n",
    "\n",
    "    layers.LocallyConnected1D(556, input_shape = (data_train.shape[1],data_train.shape[2]), \n",
    "     kernel_size=30, \n",
    "     padding=\"valid\", strides=2,\n",
    "     activation=\"relu\"),\n",
    "    \n",
    "    layers.Dropout(0.7),\n",
    "    \n",
    "    layers.LocallyConnected1D(510, \n",
    "    kernel_size=20, \n",
    "    padding=\"valid\", strides=1,\n",
    "    activation=\"relu\"),\n",
    "    \n",
    "    layers.Dropout(0.8),\n",
    "    \n",
    "    layers.Dense(units=200, activation=\"relu\"),\n",
    "    \n",
    "    layers.Dropout(0.8),\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(units=2, activation=\"softmax\")\n",
    "\n",
    "\n",
    "])\n",
    "eeg_model.build()\n",
    "eeg_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.7056 - accuracy: 0.3833 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7120 - accuracy: 0.4500 - val_loss: 0.6919 - val_accuracy: 0.4667\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6953 - val_accuracy: 0.5333\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7091 - accuracy: 0.7000 - val_loss: 0.7063 - val_accuracy: 0.6000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5893 - accuracy: 0.7167 - val_loss: 0.7758 - val_accuracy: 0.6000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5606 - accuracy: 0.7500 - val_loss: 0.8007 - val_accuracy: 0.4667\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6244 - accuracy: 0.7667 - val_loss: 0.9593 - val_accuracy: 0.4000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5589 - accuracy: 0.8167 - val_loss: 0.9991 - val_accuracy: 0.4667\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4221 - accuracy: 0.8667 - val_loss: 1.0941 - val_accuracy: 0.5333\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1758 - accuracy: 0.9833 - val_loss: 1.2354 - val_accuracy: 0.5333\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1979 - accuracy: 0.9667 - val_loss: 1.3515 - val_accuracy: 0.4667\n",
      "Results\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6994 - accuracy: 0.4400\n",
      "1/1 [==============================] - 1s 572ms/step\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "#callback2 = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(histogram_freq=2)\n",
    "\n",
    "eeg_model.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "data_train_send = np.reshape(data_train, [data_train.shape[0], 1 , data_train.shape[1], data_train.shape[2], 1])\n",
    "#data_train_send = np.reshape(data_train, [data_train.shape[0], 1 , data_train.shape[1], data_train.shape[2], 1])\n",
    "\n",
    "data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\n",
    "#data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\n",
    "\n",
    "outputs = eeg_model.fit(data_train, labels_train, validation_split=0.2 ,callbacks=[callback], epochs=50) #\n",
    "\n",
    "print(\"Results\")\n",
    "eeg_model.evaluate(data_test, labels_test)\n",
    "result = eeg_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model6\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eeg_model.save('saved_model/my_model6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6983 - accuracy: 0.4400\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[0.5503834  0.44961667]\n",
      " [0.55808246 0.4419175 ]\n",
      " [0.53748953 0.46251044]\n",
      " [0.5412001  0.45879987]\n",
      " [0.553485   0.446515  ]\n",
      " [0.5389121  0.46108785]\n",
      " [0.5191419  0.480858  ]\n",
      " [0.544229   0.45577103]\n",
      " [0.56119984 0.43880007]\n",
      " [0.5127008  0.48729923]\n",
      " [0.5005562  0.49944386]\n",
      " [0.5730843  0.4269157 ]\n",
      " [0.54295933 0.45704067]\n",
      " [0.5618551  0.4381449 ]\n",
      " [0.5176411  0.4823589 ]\n",
      " [0.5481321  0.45186788]\n",
      " [0.5289308  0.47106925]\n",
      " [0.57554406 0.42445588]\n",
      " [0.57793003 0.42206997]\n",
      " [0.55334973 0.4466503 ]\n",
      " [0.51741904 0.48258096]\n",
      " [0.5425336  0.45746642]\n",
      " [0.53369397 0.4663061 ]\n",
      " [0.502013   0.49798694]\n",
      " [0.51821274 0.4817873 ]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results\")\n",
    "eeg_model.evaluate(data_test, labels_test)\n",
    "result = eeg_model.predict(data_test)\n",
    "\n",
    "result2 = []\n",
    "print(result)\n",
    "for res in result:\n",
    "    x = np.maximum(res[0], res[1])\n",
    "    result2.append(int(np.where(res == x)[0]))\n",
    "\n",
    "result2 = np.array(result2)\n",
    "print(result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ForMasterBelgium')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "069d677023565e6a5ddf17d1b4984613dfef886b8c4d74c12f77b96d6ea71cdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
