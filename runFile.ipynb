{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataLoader as dl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import util as ut\n",
    "\n",
    "#from Inner_Speech_Dataset.Plotting.ERPs import \n",
    "from Inner_Speech_Dataset.Python_Processing.Data_extractions import  Extract_data_from_subject\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Select_time_window, Transform_for_classificator, Split_trial_in_time\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Calculate_power_windowed\n",
    "from Inner_Speech_Dataset.Python_Processing.Utilitys import picks_from_channels\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import Average_in_frec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: [trials x channels x samples]\n",
      "(500, 128, 128)\n",
      "Labels shape\n",
      "(500, 4)\n",
      "Final data shape\n",
      "(100, 128, 128)\n",
      "Final labels shape\n",
      "(100,)\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "Up is 0.0 and Down is 1.0\n",
      "(788, 128, 128)\n",
      "(788, 128, 2)\n",
      "buckets\n",
      "[[ 0  3]\n",
      " [ 3  9]\n",
      " [ 9 21]\n",
      " [21 41]\n",
      " [40 63]]\n",
      "(788, 128, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sampling_rate = 128\n",
    "nr_of_datasets=8\n",
    "data, labels = dl.load_multiple_datasets(nr_of_datasets=nr_of_datasets, sampling_rate=sampling_rate, t_min=2, t_max=3)\n",
    "\n",
    "ch_names = ut.get_channelNames()\n",
    "\n",
    "print(data.shape)\n",
    "data_p =  ut.get_power_array(data[:,:128,:], sampling_rate, trialSplit=1).squeeze()\n",
    "print(data_p.shape)\n",
    "#print(data_p[:,:,1])\n",
    "\n",
    "#Getting Freq Data \n",
    "nr_of_buckets = 5\n",
    "buckets = ut.createFreqBuckets(data[:,:128,:], nr_of_buckets)\n",
    "print(\"buckets\")\n",
    "print(buckets)\n",
    "data_f = ut.data_into_freq_buckets(data[:,:128,:], nr_of_buckets, buckets)\n",
    "#data_f = np.concatenate([dataf, np.zeros([data_f.shape[0], nr_of_datasets, data_f.shape[2]])], axis=1)\n",
    "\n",
    "print(data_f.shape)\n",
    "\n",
    "\n",
    "## Normalize data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(788, 128, 5)\n",
      "(788, 128, 2)\n",
      "(788, 2)\n",
      "[1.01648499e-10 5.52805943e-11]\n",
      "(788, 128, 135)\n",
      "(788, 128, 135)\n",
      "(788, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data_f.shape)\n",
    "print(data_p.shape)\n",
    "print(labels.shape)\n",
    "print(data_p[2,5])\n",
    "data = np.concatenate([data_f, data_p, data], axis =2 )\n",
    "print(data.shape)\n",
    "data = keras.utils.normalize(data, axis=1, order=2)\n",
    "print(data.shape)\n",
    "#print(data[2,5])\n",
    "#print(labels[2])\n",
    "print(labels[:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 2)\n",
      "(591, 128, 135)\n",
      "(197, 128, 135)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into training and test data\n",
    "#print(labels)\n",
    "\n",
    "\n",
    "order = np.arange(labels.shape[0])\n",
    "np.random.shuffle(order)\n",
    "\n",
    "temp_data = np.zeros(data.shape)\n",
    "temp_labels = np.zeros(labels.shape)\n",
    "\n",
    "for x in range(labels.shape[0]):\n",
    "    i = order[x]\n",
    "    \n",
    "    temp_data[x] = data[i]\n",
    "    temp_labels[x] = labels[i]\n",
    "\n",
    "data = temp_data\n",
    "labels = temp_labels\n",
    "\n",
    "data_train, data_test = np.split(data, indices_or_sections=[int(labels.shape[0]*0.75)],axis=0)\n",
    "labels_train, labels_test = np.split(labels, indices_or_sections=[int(labels.shape[0]*0.75)],axis=0)\n",
    "print(labels_train.shape)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " locally_connected1d (Locall  (None, 50, 56)           11342800  \n",
      " yConnected1D)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 56)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50, 500)           28500     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50, 500)           0         \n",
      "                                                                 \n",
      " locally_connected1d_1 (Loca  (None, 31, 10)           3100310   \n",
      " llyConnected1D)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 31, 10)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 31, 200)           2200      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 31, 200)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6200)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 12402     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,486,212\n",
      "Trainable params: 14,486,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eeg_model = tf.keras.Sequential([\n",
    "    \n",
    "\n",
    "    layers.LocallyConnected1D(56, input_shape = (data_train.shape[1],data_train.shape[2]), \n",
    "     kernel_size=30, \n",
    "     padding=\"valid\", strides=2,\n",
    "     activation=\"relu\"),\n",
    "    \n",
    "    layers.Dropout(0.7),\n",
    "    \n",
    "    layers.LocallyConnected1D(10, \n",
    "    kernel_size=20, \n",
    "    padding=\"valid\", strides=1,\n",
    "    activation=\"relu\"),\n",
    "    \n",
    "    layers.Dropout(0.8),\n",
    "    \n",
    "    layers.Dense(units=200, activation=\"relu\"),\n",
    "    \n",
    "    layers.Dropout(0.8),\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(units=2, activation=\"softmax\")\n",
    "\n",
    "\n",
    "])\n",
    "eeg_model.build()\n",
    "eeg_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 5s 214ms/step - loss: 0.7037 - accuracy: 0.4953 - val_loss: 0.6959 - val_accuracy: 0.4500\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 0.7103 - accuracy: 0.5141 - val_loss: 0.6942 - val_accuracy: 0.4333\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 3s 193ms/step - loss: 0.7142 - accuracy: 0.4972 - val_loss: 0.6975 - val_accuracy: 0.4667\n",
      "Epoch 4/50\n",
      " 5/17 [=======>......................] - ETA: 2s - loss: 0.7181 - accuracy: 0.5188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\PythonProjects\\NietoExcercise-1\\classTest.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m data_test_send \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(data_test, [data_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m , data_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], data_test\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], \u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m eeg_model\u001b[39m.\u001b[39;49mfit(data_train, labels_train, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m ,callbacks\u001b[39m=\u001b[39;49m[callback], epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m) \u001b[39m#\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mResults\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268656d6d614a756c696132227d/f%3A/PythonProjects/NietoExcercise-1/classTest.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m eeg_model\u001b[39m.\u001b[39mevaluate(data_test, labels_test)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Luna\\anaconda3\\envs\\ForMasterBelgium\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "#callback2 = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(histogram_freq=2)\n",
    "\n",
    "eeg_model.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "data_train_send = np.reshape(data_train, [data_train.shape[0], 1 , data_train.shape[1], data_train.shape[2], 1])\n",
    "#data_train_send = np.reshape(data_train, [data_train.shape[0], 1 , data_train.shape[1], data_train.shape[2], 1])\n",
    "\n",
    "data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\n",
    "#data_test_send = np.reshape(data_test, [data_test.shape[0], 1 , data_test.shape[1], data_test.shape[2], 1])\n",
    "\n",
    "outputs = eeg_model.fit(data_train, labels_train, validation_split=0.1 ,callbacks=[callback], epochs=50) #\n",
    "\n",
    "print(\"Results\")\n",
    "eeg_model.evaluate(data_test, labels_test)\n",
    "result = eeg_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model6\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eeg_model.save('saved_model/my_model6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 0.6953 - accuracy: 0.4619\n",
      "7/7 [==============================] - 1s 123ms/step\n",
      "[[0.47737655 0.52262354]\n",
      " [0.38966712 0.6103329 ]\n",
      " [0.47881296 0.521187  ]\n",
      " [0.47822347 0.52177656]\n",
      " [0.4693499  0.53065014]\n",
      " [0.4776438  0.5223562 ]\n",
      " [0.47772625 0.5222737 ]\n",
      " [0.4635916  0.5364084 ]\n",
      " [0.47336978 0.5266303 ]\n",
      " [0.46468732 0.53531265]\n",
      " [0.47645646 0.5235436 ]\n",
      " [0.476968   0.523032  ]\n",
      " [0.47442225 0.5255778 ]\n",
      " [0.47561613 0.52438384]\n",
      " [0.462317   0.537683  ]\n",
      " [0.4646464  0.53535354]\n",
      " [0.3883958  0.6116042 ]\n",
      " [0.47151524 0.5284848 ]\n",
      " [0.45204785 0.5479521 ]\n",
      " [0.47794533 0.5220547 ]\n",
      " [0.43207544 0.56792456]\n",
      " [0.45140547 0.5485946 ]\n",
      " [0.47822794 0.521772  ]\n",
      " [0.4631676  0.53683245]\n",
      " [0.47533414 0.5246659 ]\n",
      " [0.4682925  0.5317075 ]\n",
      " [0.47703227 0.5229677 ]\n",
      " [0.47797903 0.52202094]\n",
      " [0.42021608 0.5797839 ]\n",
      " [0.46835703 0.53164303]\n",
      " [0.47778246 0.52221763]\n",
      " [0.47732425 0.52267575]\n",
      " [0.45689324 0.54310673]\n",
      " [0.46090165 0.5390983 ]\n",
      " [0.41844654 0.5815534 ]\n",
      " [0.46778393 0.532216  ]\n",
      " [0.42523128 0.5747688 ]\n",
      " [0.4592637  0.54073626]\n",
      " [0.46927673 0.5307233 ]\n",
      " [0.4602691  0.5397309 ]\n",
      " [0.40659925 0.5934007 ]\n",
      " [0.4211809  0.5788191 ]\n",
      " [0.4765577  0.5234423 ]\n",
      " [0.46305537 0.5369446 ]\n",
      " [0.46543005 0.5345699 ]\n",
      " [0.44647586 0.5535241 ]\n",
      " [0.4273978  0.5726023 ]\n",
      " [0.45575052 0.54424953]\n",
      " [0.47768745 0.52231264]\n",
      " [0.47286916 0.52713084]\n",
      " [0.47178537 0.52821463]\n",
      " [0.47767657 0.5223234 ]\n",
      " [0.4786227  0.52137727]\n",
      " [0.37229174 0.62770826]\n",
      " [0.47781163 0.5221884 ]\n",
      " [0.4779577  0.52204233]\n",
      " [0.4786112  0.52138877]\n",
      " [0.40900084 0.5909992 ]\n",
      " [0.46869352 0.5313065 ]\n",
      " [0.4708792  0.5291208 ]\n",
      " [0.41932574 0.58067423]\n",
      " [0.47883013 0.5211699 ]\n",
      " [0.40327948 0.5967205 ]\n",
      " [0.4760297  0.5239703 ]\n",
      " [0.45047835 0.5495216 ]\n",
      " [0.46706203 0.532938  ]\n",
      " [0.44723403 0.55276597]\n",
      " [0.47662395 0.52337605]\n",
      " [0.45988756 0.5401125 ]\n",
      " [0.47878534 0.52121466]\n",
      " [0.44002804 0.5599719 ]\n",
      " [0.4308485  0.56915146]\n",
      " [0.4228876  0.5771124 ]\n",
      " [0.4748878  0.52511215]\n",
      " [0.42954224 0.5704577 ]\n",
      " [0.4506463  0.54935366]\n",
      " [0.45506805 0.544932  ]\n",
      " [0.44473073 0.5552693 ]\n",
      " [0.47873524 0.5212648 ]\n",
      " [0.4561036  0.5438963 ]\n",
      " [0.47789812 0.5221019 ]\n",
      " [0.45895004 0.54104996]\n",
      " [0.47894466 0.52105534]\n",
      " [0.4790051  0.52099484]\n",
      " [0.4716401  0.5283599 ]\n",
      " [0.47685674 0.52314323]\n",
      " [0.46479902 0.535201  ]\n",
      " [0.44130605 0.55869395]\n",
      " [0.39656913 0.6034308 ]\n",
      " [0.47633168 0.5236683 ]\n",
      " [0.4702643  0.5297357 ]\n",
      " [0.47749487 0.52250516]\n",
      " [0.47712505 0.52287495]\n",
      " [0.41252503 0.587475  ]\n",
      " [0.42556983 0.57443017]\n",
      " [0.47716057 0.5228394 ]\n",
      " [0.37623098 0.62376904]\n",
      " [0.47848552 0.52151453]\n",
      " [0.47813624 0.52186376]\n",
      " [0.47832775 0.52167225]\n",
      " [0.39692014 0.60307986]\n",
      " [0.46423846 0.5357615 ]\n",
      " [0.47807348 0.52192646]\n",
      " [0.47742724 0.5225727 ]\n",
      " [0.4686736  0.5313264 ]\n",
      " [0.4761539  0.52384615]\n",
      " [0.46415344 0.5358466 ]\n",
      " [0.40874892 0.591251  ]\n",
      " [0.4783392  0.5216608 ]\n",
      " [0.45029855 0.54970145]\n",
      " [0.46888977 0.5311102 ]\n",
      " [0.4781486  0.5218514 ]\n",
      " [0.45899016 0.54100984]\n",
      " [0.42704874 0.57295126]\n",
      " [0.46023735 0.5397627 ]\n",
      " [0.47852606 0.52147394]\n",
      " [0.46105352 0.53894645]\n",
      " [0.4772265  0.5227735 ]\n",
      " [0.47585136 0.5241487 ]\n",
      " [0.47030595 0.52969396]\n",
      " [0.4779967  0.52200323]\n",
      " [0.46668014 0.5333199 ]\n",
      " [0.46712437 0.5328756 ]\n",
      " [0.47759566 0.5224043 ]\n",
      " [0.4768057  0.5231943 ]\n",
      " [0.47815382 0.52184623]\n",
      " [0.47792843 0.5220716 ]\n",
      " [0.45028725 0.5497127 ]\n",
      " [0.4610364  0.53896356]\n",
      " [0.4614034  0.5385966 ]\n",
      " [0.38581896 0.614181  ]\n",
      " [0.47027895 0.5297211 ]\n",
      " [0.47828573 0.5217143 ]\n",
      " [0.4677453  0.53225464]\n",
      " [0.47173136 0.5282686 ]\n",
      " [0.45859075 0.5414092 ]\n",
      " [0.478309   0.521691  ]\n",
      " [0.47863138 0.5213687 ]\n",
      " [0.40741268 0.5925873 ]\n",
      " [0.47031558 0.5296844 ]\n",
      " [0.43535432 0.56464565]\n",
      " [0.4254659  0.5745341 ]\n",
      " [0.4287998  0.5712002 ]\n",
      " [0.4603323  0.53966767]\n",
      " [0.43731973 0.56268024]\n",
      " [0.43681586 0.5631842 ]\n",
      " [0.47432524 0.5256747 ]\n",
      " [0.46270537 0.5372947 ]\n",
      " [0.46388534 0.53611463]\n",
      " [0.4120974  0.5879026 ]\n",
      " [0.47334832 0.52665174]\n",
      " [0.4259845  0.5740155 ]\n",
      " [0.41114476 0.58885527]\n",
      " [0.47854382 0.52145624]\n",
      " [0.47828314 0.52171683]\n",
      " [0.4393684  0.56063163]\n",
      " [0.46476033 0.5352397 ]\n",
      " [0.43905511 0.56094486]\n",
      " [0.40538305 0.59461695]\n",
      " [0.45899057 0.54100937]\n",
      " [0.45933723 0.54066277]\n",
      " [0.43087596 0.5691241 ]\n",
      " [0.43111908 0.5688809 ]\n",
      " [0.42613444 0.5738656 ]\n",
      " [0.43599346 0.56400657]\n",
      " [0.42832184 0.5716782 ]\n",
      " [0.4772612  0.5227389 ]\n",
      " [0.4758061  0.5241939 ]\n",
      " [0.42486426 0.57513577]\n",
      " [0.46195918 0.5380408 ]\n",
      " [0.4709541  0.529046  ]\n",
      " [0.47630048 0.5236996 ]\n",
      " [0.47646287 0.5235371 ]\n",
      " [0.46365702 0.5363429 ]\n",
      " [0.47879916 0.5212008 ]\n",
      " [0.47239432 0.52760565]\n",
      " [0.47403416 0.5259658 ]\n",
      " [0.4550121  0.5449879 ]\n",
      " [0.4590749  0.5409251 ]\n",
      " [0.46462744 0.53537256]\n",
      " [0.477528   0.52247196]\n",
      " [0.4764677  0.5235323 ]\n",
      " [0.40972254 0.5902775 ]\n",
      " [0.43403623 0.56596375]\n",
      " [0.47222564 0.5277744 ]\n",
      " [0.47696066 0.5230394 ]\n",
      " [0.47301996 0.52698004]\n",
      " [0.47817668 0.52182335]\n",
      " [0.47463155 0.5253685 ]\n",
      " [0.4758559  0.5241441 ]\n",
      " [0.41760942 0.58239067]\n",
      " [0.46333492 0.536665  ]\n",
      " [0.42560232 0.5743977 ]\n",
      " [0.47360882 0.52639115]\n",
      " [0.44903573 0.55096424]\n",
      " [0.47832814 0.5216719 ]\n",
      " [0.42027542 0.57972455]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results\")\n",
    "eeg_model.evaluate(data_test, labels_test)\n",
    "result = eeg_model.predict(data_test)\n",
    "\n",
    "result2 = []\n",
    "print(result)\n",
    "for res in result:\n",
    "    x = np.maximum(res[0], res[1])\n",
    "    result2.append(int(np.where(res == x)[0]))\n",
    "\n",
    "result2 = np.array(result2)\n",
    "print(result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ForMasterBelgium')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "069d677023565e6a5ddf17d1b4984613dfef886b8c4d74c12f77b96d6ea71cdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
